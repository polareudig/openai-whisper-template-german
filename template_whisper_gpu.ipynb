{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a699401-d196-48f7-9a4c-71842cffb980",
   "metadata": {},
   "source": [
    "# Openai whisper Template (GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a05a01e-235e-4984-8c12-167e19d4341b",
   "metadata": {},
   "source": [
    "Das ist ein kleines Notebook, was einem hilft auf einer GPU eine Transkription einer Audio-Datei zu erstellen mit dem openai whisper package.\n",
    "Im Grunde muss nur der Name der Datei ausgetauscht werden. \n",
    "<br>\n",
    "Whisper: https://github.com/openai/whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "273db2e2-e1f2-4fc2-9858-3696be228b0e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai-whisper in /opt/conda/lib/python3.9/site-packages (20240930)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.9/site-packages (from openai-whisper) (2.5.0)\n",
      "Requirement already satisfied: triton>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from openai-whisper) (3.1.0)\n",
      "Requirement already satisfied: tiktoken in /opt/conda/lib/python3.9/site-packages (from openai-whisper) (0.8.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from openai-whisper) (1.22.4)\n",
      "Requirement already satisfied: numba in /opt/conda/lib/python3.9/site-packages (from openai-whisper) (0.55.2)\n",
      "Requirement already satisfied: more-itertools in /opt/conda/lib/python3.9/site-packages (from openai-whisper) (10.5.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from openai-whisper) (4.64.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from triton>=2.0.0->openai-whisper) (3.16.1)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /opt/conda/lib/python3.9/site-packages (from numba->openai-whisper) (0.38.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from numba->openai-whisper) (63.1.0)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.9/site-packages (from tiktoken->openai-whisper) (2.28.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.9/site-packages (from tiktoken->openai-whisper) (2024.9.11)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.9/site-packages (from torch->openai-whisper) (2.21.5)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.9/site-packages (from torch->openai-whisper) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.9/site-packages (from torch->openai-whisper) (12.4.127)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from torch->openai-whisper) (3.1.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.9/site-packages (from torch->openai-whisper) (2.8.4)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.9/site-packages (from torch->openai-whisper) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.9/site-packages (from torch->openai-whisper) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.9/site-packages (from torch->openai-whisper) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.9/site-packages (from torch->openai-whisper) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.9/site-packages (from torch->openai-whisper) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.9/site-packages (from torch->openai-whisper) (12.4.127)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.9/site-packages (from torch->openai-whisper) (2022.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.9/site-packages (from torch->openai-whisper) (4.12.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.9/site-packages (from torch->openai-whisper) (12.4.127)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.9/site-packages (from torch->openai-whisper) (10.3.5.147)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.9/site-packages (from torch->openai-whisper) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.9/site-packages (from torch->openai-whisper) (12.4.127)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.9/site-packages (from sympy==1.13.1->torch->openai-whisper) (1.2.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2022.6.15)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->torch->openai-whisper) (2.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c708be54-9f05-45f1-9ad8-9004b3566c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ffmpeg-python in /opt/conda/lib/python3.9/site-packages (0.2.0)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.9/site-packages (from ffmpeg-python) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ffmpeg-python #Eine notwendige AbhÃ¤ngigkeit, damit whisper funktioniert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ae5708b-a539-4f46-80be-c2a1787e3b86",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/conda/lib/python3.9/site-packages (2.5.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.9/site-packages (0.20.0)\n",
      "Requirement already satisfied: torchaudio in /opt/conda/lib/python3.9/site-packages (2.5.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.9/site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.9/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.9/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.9/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.9/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.9/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.9/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.9/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.9/site-packages (from torch) (2022.5.0)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.9/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.9/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/conda/lib/python3.9/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.9/site-packages (from sympy==1.13.1->torch) (1.2.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from torchvision) (1.22.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.9/site-packages (from torchvision) (9.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->torch) (2.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250d0a42-3e62-4a4a-8643-948950d53d94",
   "metadata": {},
   "source": [
    "## Belegung der Grafikkarte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e836883-200f-4c39-965c-2810f5e98c99",
   "metadata": {},
   "source": [
    "Hinweis: Das meiste hier ist optional. Es ist aber immer sinnvoll zu sehen, wie hoch die aktuelle Auslastung der GPU ist <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4dbe448-17d8-4074-87dc-f93cb29423a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch CUDA Version: 12.4\n",
      "torchvision CUDA Version: 0.20.0+cu124\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "print(f\"PyTorch CUDA Version: {torch.version.cuda}\")\n",
    "print(f\"torchvision CUDA Version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "490d9d26-bab5-438c-b95e-3ee79e8fa610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Oct 22 18:41:33 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.125.06   Driver Version: 525.125.06   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:4B:00.0 Off |                  N/A |\n",
      "| 30%   42C    P8    20W / 250W |   1041MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9904c9b-e51f-4ceb-8068-a169edac32d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Belegter Speicher: 0.00 GB\n",
      "Reservierter Speicher: 0.00 GB\n",
      "Freier Speicher: 10.75 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Speicherinformationen abrufen\n",
    "gpu_memory_allocated = torch.cuda.memory_allocated() / 1024**3  # In GB\n",
    "gpu_memory_reserved = torch.cuda.memory_reserved() / 1024**3  # In GB\n",
    "gpu_memory_free = torch.cuda.get_device_properties(0).total_memory / 1024**3 - gpu_memory_reserved  # In GB\n",
    "\n",
    "print(f\"Belegter Speicher: {gpu_memory_allocated:.2f} GB\")\n",
    "print(f\"Reservierter Speicher: {gpu_memory_reserved:.2f} GB\")\n",
    "print(f\"Freier Speicher: {gpu_memory_free:.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6078a751-61c2-4123-b3ea-5f841de658b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "pray_to_cuda = torch.cuda.empty_cache()\n",
    "print(pray_to_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6fb7d8-7536-4187-8429-d8e8ac223f44",
   "metadata": {},
   "source": [
    "*PrÃ¼fen, ob cuda verfÃ¼gbar ist um auf der GPU zu rendern*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a61f2e3-79aa-4d47-a4f7-aa85767bc732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "NVIDIA GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# PrÃ¼fen, ob CUDA verfÃ¼gbar ist\n",
    "print(torch.cuda.is_available())  # Gibt 'True' zurÃ¼ck, wenn eine GPU verfÃ¼gbar ist\n",
    "\n",
    "# PrÃ¼fen, wie viele GPUs verfÃ¼gbar sind\n",
    "print(torch.cuda.device_count())\n",
    "\n",
    "# Den Namen der GPU abrufen\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))  # 0 ist der Index der ersten GPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac93b80-2716-4fe9-98a1-e6f71b1600c9",
   "metadata": {},
   "source": [
    "## Modell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba59c90-d895-46f7-8f3f-a1eac6595212",
   "metadata": {},
   "source": [
    "Hinweis 1: Das Test-Audio funktioniert mit allen Modellen von tiny bis medium. <br> Hinweis 2: Es lohnt sich bei einer Videodatei zu testen, vorher die Tonspur zu extrahieren, um schnellere und bessere Ergebnisse zu bekommen. <br>\n",
    "Hinweis 3: .to(device) legt das Modell auf die GPU. Dazu wie folgend die Variable device definieren. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea4c15f6-5ab8-4adc-8eec-e421a71a4a20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import torch\n",
    "\n",
    "# Sicherstellen, dass die GPU verwendet wird, falls verfÃ¼gbar\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "# Lade das Whisper-Modell und verschiebe es auf die GPU (falls verfÃ¼gbar)\n",
    "model = whisper.load_model(\"medium\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38456dbb-33c2-48d6-89bb-98b692cd23a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480000,)\n",
      "torch.Size([80, 3000])\n"
     ]
    }
   ],
   "source": [
    "# load audio and pad/trim it to fit 30 seconds\n",
    "audio_file = \"audio/test.mp3\"  #Hier den Dateinamen austauschen! \n",
    "audio = whisper.load_audio(audio_file)\n",
    "audio = whisper.pad_or_trim(audio)\n",
    "\n",
    "# PrÃ¼fen, wie viele KanÃ¤le die Audiodatei hat (wichtig, um zu sehen, ob der Input fÃ¼r das Modell passt)\n",
    "print(audio.shape)\n",
    "\n",
    "# Log-Mel-Spektrogramm erstellen\n",
    "mel = whisper.log_mel_spectrogram(audio).to(device)\n",
    "\n",
    "# PrÃ¼fe die Dimensionen des Mel-Spektrogramms\n",
    "print(mel.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7e0add-f18a-44ff-8865-5c1f93454325",
   "metadata": {},
   "source": [
    "*Hinweis*\n",
    "\n",
    "Mel-Skala: Logarithmische Skala, die die menschliche Wahrnehmung von TonhÃ¶hen nachahmt.\n",
    "\n",
    "Mel-Spektrogramm: Spektrogramm, das Frequenzen auf der Mel-Skala darstellt, um das menschliche GehÃ¶r besser widerzuspiegeln.\n",
    "\n",
    "Verwendung: Wird in der Sprachverarbeitung und Audioanalyse eingesetzt, um die Audioinformationen so darzustellen, dass sie fÃ¼r maschinelle Lernmodelle besser zugÃ¤nglich sind."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208ff415-bbf6-4ac4-adcd-90249b8da06e",
   "metadata": {},
   "source": [
    "## Transkript Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532a213f-c493-4761-b02d-5cce69208171",
   "metadata": {},
   "source": [
    "Festlegen der Optionen <br>\n",
    "Funktion zur Anpassung des Outputs (Timestamps, Speaker etc.) <br>\n",
    "Speichern des Outputs in einer .txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17e4f1d6-ecf8-449c-99e5-44a061ee7b11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: de\n",
      "[00:00 - 00:06]  Es ist Feierabend in der Krossenkrabbe und Tadeusz beantwortet einen letzten Anruf von einem Kunden.\n",
      "[00:06 - 00:16]  Gerade als er ihnen sagen will, dass das Restaurant geschlossen ist, erscheint der Chef plÃ¶tzlich und schnappt sich das Telefon von Tadeusz.\n",
      "[00:16 - 00:26]  Der Kunde mÃ¶chte eine Pizza bestellen und geliefert bekommen, eine Bestellung, die er gerne annimmt, da er weiÃ, dass er zusÃ¤tzliches Geld verdienen kann.\n",
      "[00:26 - 00:33]  Tadeusz protestiert damit, indem er sagt, dass das Restaurant keine Pizza liefert.\n"
     ]
    }
   ],
   "source": [
    "# make log-Mel spectrogram and move to the same device as the model\n",
    "mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "\n",
    "# detect the spoken language\n",
    "_, probs = model.detect_language(mel)\n",
    "print(f\"Detected language: {max(probs, key=probs.get)}\")\n",
    "\n",
    "# Dekodierungsoptionen mit aktiviertem \"timestamps\"\n",
    "options = whisper.DecodingOptions(fp16=True, language=\"de\", task=\"transcribe\")\n",
    "\n",
    "# Dekodiere das Audio mit Timestamps\n",
    "result = model.transcribe(audio_file, fp16=True)\n",
    "\n",
    "# Funktion zum Formatieren der Timestamps in Minuten:Sekunden\n",
    "def format_timestamp(seconds):\n",
    "    minutes = int(seconds // 60)\n",
    "    seconds = int(seconds % 60)\n",
    "    return f\"{minutes:02d}:{seconds:02d}\"\n",
    "\n",
    "\n",
    "# Falls es mehr als 2 Sprechende im Audio gibt mÃ¼ssen alle mit \"a\" gekennzeichneten Zeilen entkommentiert werden\n",
    "\n",
    "#a Wechselnde Sprecher: \"A\", \"B\"\n",
    "#a speakers = [\"A\", \"B\"]\n",
    "#a current_speaker = 0\n",
    "\n",
    "# Erkannten Text und Timestamps in Minuten ausgeben\n",
    "for segment in result['segments']:\n",
    "    start = format_timestamp(segment['start'])\n",
    "    end = format_timestamp(segment['end'])\n",
    "    text = segment['text']\n",
    "    #a speaker = speakers[current_speaker]\n",
    "    print(f\"[{start} - {end}] {text}\")\n",
    "    \n",
    "    #a Sprecher wechseln: A -> B -> A -> B usw.\n",
    "    #a current_speaker = (current_speaker + 1) % 2\n",
    "    \n",
    "    #a print(f\"[{start} - {end}] {speaker}: {text}\")\n",
    "        \n",
    "        \n",
    "# Erkannten Text, Timestamps und Sprecherangaben in eine .txt-Datei speichern\n",
    "with open(\"output/transcript_gpu.txt\", \"w\") as file:\n",
    "    current_speaker = 0  # Setze den Sprecher zurÃ¼ck\n",
    "    for segment in result['segments']:\n",
    "        start = format_timestamp(segment['start'])\n",
    "        end = format_timestamp(segment['end'])\n",
    "        text = segment['text']\n",
    "        #a speaker = speakers[current_speaker]\n",
    "\n",
    "        #a Sprecher wechseln: A -> B -> A -> B\n",
    "        #a current_speaker = (current_speaker + 1) % 2\n",
    "\n",
    "        file.write(f\"[{start} - {end}] {speaker}: {text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f51e8e-d477-47cd-a494-2e2e375a4552",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
